# Projet_7_OC

### Dossier GitHub comprenant les différents éléments réalisés dans le cadre de mon Projet 7 du parcours Data Scientist d'OpenClassrooms.

Ce projet ce base sur le dataset de la compétition Kaggle disponible [ici](https://www.kaggle.com/competitions/home-credit-default-risk/overview). Le but initial de cette compétiion étant de mettre en place un modèle de classification permettant de prédire si un client va être ou non en mesure ce rembourser un prêt dont il fait la demande, et donc de décider d'accorder ou non le prêt selon la prédiction.

Vous pouvez retrouver ici un bref explicatif des différentes étapes qui constituent le projet, pour plus de détails sur la démarche et l'approche technique, veuillez vous référez directement à la note technique.

Pour résoudre ce problème on a accès à une database contenant de nombreuses informations sur chaque client unique identifié par un ID_CLIENT. La première étape sera évidemment de traiter ces données brutes afin d'en obtenir le plus d'informations intéressantes pour entraîner notre modèle. Comme recommandé dans l'énoncé du projet, j'ai décidé de prendre un feature engineering préfait par un participant à la compétition Kaggle afin de faciliter le travail. J'ai évidemment appliqué quelques modifications à ce script afin d'en faciliter la compréhension et l'utilisation.

Après avoir traité les données, on va commencer par une étude afin de trouver le meilleur modèle à utiliser pour ce projet. Pour cela on va mettre en place différents algorithmes de classification afin de comparer leurs performances, et une fois qu'on aura sélectionné le plus performant on pourra appliquer différentes fonctions de cross validation afin d'optimiser les hyperparamètres et d'obtenir les meilleurs résultats possibles avec notre modèle. Toutes ces études sont à retrouver au sein du notebook jupyter sur le GitHub.

Une fois qu'on a sélectionner le meilleur modèle pour notre projet, on passe à une étape de cross validation afin d'optimiser les hyperparamètres de notre modèle. On exporte ensuite le modèle obtenu afin de pouvoir le réutiliser dans notre API.

On souhaite maintenant pouvoir communiquer les résultats obtenus pour chaque demande de prêt au client concerné. Pour cela on souhaite donc mettre en place un dashboard interactif, qui ferait appel à une API afin de récupérer les informations du client via le modèle et la base de données. Sur ce dashboard, le client pourrait obtenir directement le résutat de sa demande ainsi que son "score". Il pourra également afficher des détails sur ses données afin de mieux comprendre le résultat de sa demande. Le dashboard ainsi que l'API sont ensuite déployés sur le cloud afin de permettre un accès à tous les utilisateurs différemment.

Pour ce déploiement, on a d'un côté dans le dossier API, contenant l'application Spark chargée de répondre aux requêtes en d'envoyer les données de l'utilisateur qui envoie la requête. Cette application récupère les données à partir des deux datasets df_train et df_test, qui contiennent les données traitées et nettoyées de tous les clients, dont on a ici pris un échantillon car Github limite la taille des fichiers dans les repositeries. Elle se sert également du modèle qu'on a optimisé au cours du Notebook "Feature Engineering et création du modèle". Cette API est déployée sur Amazon ECS grâce au workflow présent dans le dossier .github, qui crée une image Docker basée sur les informations du fichier Dockerfile, le container est ensuite envoyé sur ECR, et on le récupère ensuite sur ECS grâce à a task décrite dans "fargate_task.json".

D'autre part, on a dans le dossier Dashboard l'application Streamlit, qui se charge d'envoyer une requête à l'application en demandant à l'utilisateur d'entrer son identifiant, qui correspond à la variable **SK_ID_CURR** dans les datasets. L'applocation enregistre ensuite la réponse envoyée par l'API et permet à l'utilisateur de naviguer sur quelques pages afin d'observer les résultats de sa demande de prêt et des détails concernant son dossier. Le Dashboard est hébergée sur Streamlit Cloud.
